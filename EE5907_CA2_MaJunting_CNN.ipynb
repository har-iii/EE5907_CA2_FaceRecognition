{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Activation, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load image files from 'PIE' folder and 'own_image' folder.\n",
    "\n",
    "The 20 subjects out of the entire data set are selected using a random number generator to ensure randomness and prevent any bias.\n",
    "\n",
    "The images are splited into training and test sets. \n",
    "\n",
    "Preprocess images using standard scaler from sklearn package, reshape the images to fit into CNN\n",
    "\n",
    "Since sampling is not mentioned in the instructions provided, the entire training set is used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir_list = ['PIE/1/*.jpg', 'PIE/4/*.jpg', 'PIE/5/*.jpg', \\\n",
    "               'PIE/19/*.jpg', 'PIE/21/*.jpg', 'PIE/23/*.jpg', \\\n",
    "               'PIE/25/*.jpg', 'PIE/29/*.jpg', 'PIE/33/*.jpg', \\\n",
    "               'PIE/39/*.jpg', 'PIE/40/*.jpg', 'PIE/44/*.jpg', \\\n",
    "               'PIE/45/*.jpg', 'PIE/46/*.jpg', 'PIE/48/*.jpg', \\\n",
    "               'PIE/52/*.jpg', 'PIE/57/*.jpg', 'PIE/58/*.jpg', \\\n",
    "               'PIE/59/*.jpg', 'PIE/67/*.jpg']\n",
    "image_list = []\n",
    "image_own = []\n",
    "train_list = []\n",
    "train_own = []\n",
    "test_list = []\n",
    "test_own = []\n",
    "image_label = []\n",
    "own_label = [20] * 10\n",
    "\n",
    "for i in range (0, 20):\n",
    "    for filename in glob.glob(img_dir_list[i]):\n",
    "        im = Image.open(filename)\n",
    "        arr = np.array(im).flatten()\n",
    "        image_list.append(arr)\n",
    "        image_label.append(i)\n",
    "for filename in glob.glob('own_image/*.jpg'):\n",
    "    im = Image.open(filename)\n",
    "    arr = np.array(im).flatten()\n",
    "    image_own.append(arr)\n",
    "    \n",
    "image_list = np.asarray(image_list)\n",
    "image_own = np.asarray(image_own)\n",
    "image_label = np.asarray(image_label)\n",
    "own_label = np.asarray(own_label)\n",
    "\n",
    "train_list, test_list, train_label, test_label = train_test_split(image_list, image_label, test_size = 0.3)\n",
    "train_list = np.asarray(train_list)\n",
    "test_list = np.asarray(test_list)\n",
    "train_label = np.asarray(train_label)\n",
    "test_label = np.asarray(test_label)\n",
    "\n",
    "train_own, test_own, train_own_label, test_own_label = train_test_split(image_own, own_label, test_size = 0.3)\n",
    "train_own = np.asarray(train_own)\n",
    "test_own = np.asarray(test_own)\n",
    "train_own_label = np.asarray(train_own_label)\n",
    "test_own_label = np.asarray(test_own_label)\n",
    "\n",
    "test_list = np.concatenate((test_list, test_own))\n",
    "test_label = np.concatenate((test_label, test_own_label))\n",
    "train_list = np.concatenate((train_list, train_own))\n",
    "train_label = np.concatenate((train_label, train_own_label))\n",
    "\n",
    "test_list = np.asarray(test_list)\n",
    "train_list = np.asarray(train_list)\n",
    "\n",
    "sc = preprocessing.StandardScaler()\n",
    "train_list_prep = sc.fit_transform(train_list)\n",
    "test_list_prep = sc.transform(test_list)\n",
    "\n",
    "test_list = test_list_prep.reshape(test_list_prep.shape[0], 32, 32, 1)\n",
    "train_list = train_list_prep.reshape(train_list_prep.shape[0], 32, 32, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the labels array to binary matrix to fit in CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = to_categorical(test_label, num_classes = 21)\n",
    "train_label = to_categorical(train_label, num_classes = 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct neural network with 2 convolutional layers and one fully connected layer\n",
    "\n",
    "Number of nodes: 20-50-500-21\n",
    "\n",
    "Convolutional kernel size are set as 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 20)        520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 50)        25050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1600500   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 21)                10521     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 21)                0         \n",
      "=================================================================\n",
      "Total params: 1,636,591\n",
      "Trainable params: 1,636,591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=20, kernel_size=5, strides=1, padding=\"same\", input_shape=(32, 32, 1)))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=50, kernel_size=5, strides=1, padding='same'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(21))\n",
    "model.add(Activation('softmax'))\n",
    "adam = keras.optimizers.Adam(lr=1e-4)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit training data into CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2387 samples, validate on 1023 samples\n",
      "Epoch 1/20\n",
      " - 6s - loss: 2.4131 - accuracy: 0.3775 - val_loss: 1.6571 - val_accuracy: 0.6491\n",
      "Epoch 2/20\n",
      " - 6s - loss: 0.9367 - accuracy: 0.8387 - val_loss: 0.6220 - val_accuracy: 0.8456\n",
      "Epoch 3/20\n",
      " - 6s - loss: 0.3808 - accuracy: 0.9212 - val_loss: 0.3699 - val_accuracy: 0.9198\n",
      "Epoch 4/20\n",
      " - 7s - loss: 0.2056 - accuracy: 0.9585 - val_loss: 0.2428 - val_accuracy: 0.9492\n",
      "Epoch 5/20\n",
      " - 6s - loss: 0.1356 - accuracy: 0.9740 - val_loss: 0.1942 - val_accuracy: 0.9521\n",
      "Epoch 6/20\n",
      " - 6s - loss: 0.0851 - accuracy: 0.9853 - val_loss: 0.1492 - val_accuracy: 0.9648\n",
      "Epoch 7/20\n",
      " - 6s - loss: 0.0624 - accuracy: 0.9899 - val_loss: 0.1571 - val_accuracy: 0.9638\n",
      "Epoch 8/20\n",
      " - 6s - loss: 0.0448 - accuracy: 0.9925 - val_loss: 0.1331 - val_accuracy: 0.9697\n",
      "Epoch 9/20\n",
      " - 6s - loss: 0.0344 - accuracy: 0.9954 - val_loss: 0.1125 - val_accuracy: 0.9717\n",
      "Epoch 10/20\n",
      " - 6s - loss: 0.0236 - accuracy: 0.9975 - val_loss: 0.1327 - val_accuracy: 0.9677\n",
      "Epoch 11/20\n",
      " - 6s - loss: 0.0213 - accuracy: 0.9979 - val_loss: 0.1051 - val_accuracy: 0.9746\n",
      "Epoch 12/20\n",
      " - 6s - loss: 0.0135 - accuracy: 0.9996 - val_loss: 0.0960 - val_accuracy: 0.9765\n",
      "Epoch 13/20\n",
      " - 6s - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9765\n",
      "Epoch 14/20\n",
      " - 6s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9756\n",
      "Epoch 15/20\n",
      " - 6s - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9746\n",
      "Epoch 16/20\n",
      " - 6s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9756\n",
      "Epoch 17/20\n",
      " - 6s - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9775\n",
      "Epoch 18/20\n",
      " - 8s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 0.9795\n",
      "Epoch 19/20\n",
      " - 6s - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9775\n",
      "Epoch 20/20\n",
      " - 6s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22082875518>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_list, train_label, epochs=20, batch_size=32, validation_data=(test_list, test_label),\n",
    "              shuffle=True, verbose=2, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute loss and accuracy for training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data accuracy:97.75171279907227%. Loss: 0.09190742222943643\n",
      "Training data accuracy:100.0%. Loss: 0.0023320119163828304\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_list, test_label, verbose = 0)\n",
    "print(\"Test data accuracy:\" + str(test_accuracy * 100) + \"%. Loss: \" + str(test_loss))\n",
    "train_loss, train_accuracy = model.evaluate(train_list, train_label, verbose = 0)\n",
    "print(\"Training data accuracy:\" + str(train_accuracy * 100) + \"%. Loss: \" + str(train_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
